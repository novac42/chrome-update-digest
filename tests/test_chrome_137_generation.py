#!/usr/bin/env python3
"""
Chrome 137 Digestç”Ÿæˆæµ‹è¯•
é€šè¿‡MCP serverè°ƒç”¨å·¥å…·ç”ŸæˆChrome 137çš„å®Œæ•´digestæ–‡æ¡£
"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„  
sys.path.append(str(Path(__file__).parent))

# ç›´æ¥å¯¼å…¥å·¥å…·ç±»
from src.mcp_tools.enterprise_digest import EnterpriseDigestTool
from src.mcp_tools.enhanced_webplatform_digest import EnhancedWebplatformDigestTool as WebplatformDigestTool  
from src.mcp_tools.merged_digest_html import MergedDigestHtmlTool

# åˆ›å»ºä¸€ä¸ªç®€å•çš„Contextæ¨¡æ‹Ÿç±»ï¼Œé¿å…ç›´æ¥ç»§æ‰¿Context
class MockContext:
    """æ¨¡æ‹ŸFastMCPçš„Contextå¯¹è±¡ç”¨äºæµ‹è¯•"""
    def __init__(self):
        self._session_id = "test_session"
        self._request_id = "test_request" 
        self._client_id = "test_client"
    
    @property
    def session_id(self):
        return self._session_id
    
    @property
    def request_id(self):
        return self._request_id
    
    @property
    def client_id(self):
        return self._client_id
    
    async def request_sampling(self, prompt: str, max_tokens: int = 8000):
        """æ¨¡æ‹Ÿsamplingè¯·æ±‚ - è¿”å›ç®€å•çš„å ä½ç¬¦å†…å®¹"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„LLMï¼Œç°åœ¨è¿”å›å ä½ç¬¦
        return f"""# Chrome {137} Digest

## æ¦‚è¿°
è¿™æ˜¯Chrome 137ç‰ˆæœ¬çš„digestæ‘˜è¦ï¼ŒåŸºäºä»¥ä¸‹promptç”Ÿæˆï¼š

{prompt[:200]}...

## ä¸»è¦æ›´æ–°
- åŠŸèƒ½æ›´æ–°1: æè¿°ä¸€äº›é‡è¦çš„åŠŸèƒ½æ›´æ–°
- æ€§èƒ½æ”¹è¿›: æè¿°æ€§èƒ½æ–¹é¢çš„æ”¹è¿›
- å®‰å…¨æ€§å¢å¼º: æè¿°å®‰å…¨ç›¸å…³çš„æ”¹è¿›
- å¼€å‘è€…å·¥å…·: æè¿°å¼€å‘è€…ç›¸å…³çš„æ›´æ–°

## è¯¦ç»†å†…å®¹
ç”±äºè¿™æ˜¯æ¨¡æ‹Ÿç¯å¢ƒï¼Œè¿™é‡Œæ˜¾ç¤ºå ä½ç¬¦å†…å®¹ã€‚åœ¨çœŸå®ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šæ˜¯LLMæ ¹æ®æºæ•°æ®ç”Ÿæˆçš„è¯¦ç»†digestå†…å®¹ã€‚

Prompté•¿åº¦: {len(prompt)} å­—ç¬¦
æœ€å¤§tokens: {max_tokens}
ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}
"""
    
    async def sample(self, messages=None, system_prompt=None, model_preferences=None, temperature=0.7, max_tokens=4000, **kwargs):
        """æ¨¡æ‹Ÿsampleæ–¹æ³• - å·¥å…·ç±»å®é™…è°ƒç”¨çš„æ–¹æ³•"""
        if messages:
            prompt_text = "\n".join([msg.get("content", "") for msg in messages if isinstance(msg, dict)])
        else:
            prompt_text = system_prompt or "æœªçŸ¥prompt"
            
        return f"""# Chrome 137 ä¼ä¸šç‰ˆæ›´æ–°æ‘˜è¦

## æ¦‚è¿°
æœ¬æ¬¡Chrome 137ç‰ˆæœ¬å¸¦æ¥äº†å¤šé¡¹ä¼ä¸šçº§åŠŸèƒ½æ”¹è¿›ï¼Œä¸»è¦é›†ä¸­åœ¨ç”Ÿäº§åŠ›å·¥å…·ã€å®‰å…¨æ€§å¢å¼ºå’Œç®¡ç†åŠŸèƒ½ä¼˜åŒ–æ–¹é¢ã€‚

## ä¸»è¦æ›´æ–°å†…å®¹

### ğŸš€ ç”Ÿäº§åŠ›æå‡
- **æ–°å¢ä¼ä¸šçº§ä¹¦ç­¾åŒæ­¥åŠŸèƒ½**: æ”¯æŒè·¨è®¾å¤‡çš„ä¼ä¸šä¹¦ç­¾ç®¡ç†
- **æ”¹è¿›çš„PDFå¤„ç†**: å¢å¼ºäº†PDFæŸ¥çœ‹å’Œç¼–è¾‘åŠŸèƒ½
- **åŠå…¬å¥—ä»¶é›†æˆ**: æ›´å¥½çš„Microsoft Officeå’ŒGoogle Workspaceé›†æˆ

### ğŸ”’ å®‰å…¨æ€§å¢å¼º  
- **å¢å¼ºçš„è¯ä¹¦ç®¡ç†**: æ”¹è¿›äº†ä¼ä¸šè¯ä¹¦çš„éƒ¨ç½²å’Œç®¡ç†æµç¨‹
- **é«˜çº§å¨èƒé˜²æŠ¤**: æ–°å¢å¯¹é’“é±¼ç½‘ç«™çš„æ™ºèƒ½è¯†åˆ«åŠŸèƒ½
- **æ•°æ®æ³„éœ²é˜²æŠ¤**: åŠ å¼ºäº†æ•æ„Ÿæ•°æ®çš„ä¿æŠ¤æœºåˆ¶

### âš™ï¸ ç®¡ç†åŠŸèƒ½
- **ç­–ç•¥ç®¡ç†ä¼˜åŒ–**: ç®€åŒ–äº†ä¼ä¸šç­–ç•¥çš„é…ç½®å’Œéƒ¨ç½²
- **ç”¨æˆ·é…ç½®æ–‡ä»¶ç®¡ç†**: æ”¹è¿›äº†å¤šç”¨æˆ·ç¯å¢ƒä¸‹çš„é…ç½®ç®¡ç†
- **è¿œç¨‹ç®¡ç†å·¥å…·**: å¢å¼ºäº†ITç®¡ç†å‘˜çš„è¿œç¨‹æ§åˆ¶èƒ½åŠ›

### ğŸ› ï¸ å¼€å‘è€…å·¥å…·
- **è°ƒè¯•å·¥å…·æ”¹è¿›**: å‡çº§äº†å¼€å‘è€…æ§åˆ¶å°çš„åŠŸèƒ½
- **æ€§èƒ½åˆ†æå·¥å…·**: æ–°å¢äº†ç½‘é¡µæ€§èƒ½åˆ†æåŠŸèƒ½
- **æ‰©å±•APIæ›´æ–°**: ä¸ºä¼ä¸šæ‰©å±•å¼€å‘æä¾›äº†æ–°çš„API

## éƒ¨ç½²å»ºè®®
- å»ºè®®ä¼ä¸šç”¨æˆ·ä¼˜å…ˆæµ‹è¯•æ–°çš„å®‰å…¨åŠŸèƒ½
- æ–°çš„ç®¡ç†ç­–ç•¥éœ€è¦é…åˆæœ€æ–°çš„ç®¡ç†æ§åˆ¶å°ä½¿ç”¨
- å»ºè®®åˆ†é˜¶æ®µéƒ¨ç½²ï¼Œå…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯

## å½±å“è¯„ä¼°
- å…¼å®¹æ€§: ä¸ç°æœ‰ä¼ä¸šåº”ç”¨ä¿æŒè‰¯å¥½å…¼å®¹æ€§
- æ€§èƒ½: æ•´ä½“æ€§èƒ½æå‡çº¦5-10%
- å®‰å…¨æ€§: æ˜¾è‘—æå‡äº†ä¼ä¸šæ•°æ®å®‰å…¨ä¿æŠ¤èƒ½åŠ›

---
*åŸºäºæ¨¡æ‹ŸLLMç”Ÿæˆçš„æ‘˜è¦å†…å®¹*
*æ¨¡å‹åå¥½: {model_preferences}*
*æ¸©åº¦è®¾ç½®: {temperature}*
*æœ€å¤§tokens: {max_tokens}*
"""
    
    async def info(self, message: str, logger_name: str = "test"):
        """è®°å½•ä¿¡æ¯"""
        print(f"INFO: {message}")
    
    async def debug(self, message: str, logger_name: str = "test"):
        """è®°å½•è°ƒè¯•ä¿¡æ¯"""
        print(f"DEBUG: {message}")
    
    async def warning(self, message: str, logger_name: str = "test"):
        """è®°å½•è­¦å‘Š"""
        print(f"WARNING: {message}")
    
    async def error(self, message: str, logger_name: str = "test"):
        """è®°å½•é”™è¯¯"""
        print(f"ERROR: {message}")
    
    async def report_progress(self, progress: float, total: float = 100.0, message: str = ""):
        """æŠ¥å‘Šè¿›åº¦"""
        if total:
            print(f"PROGRESS: {progress}/{total} ({progress/total*100:.1f}%) {message}")
        else:
            print(f"PROGRESS: {progress} {message}")

# åŸºç¡€è·¯å¾„
BASE_PATH = Path(__file__).parent


async def generate_chrome_137_digests():
    """ç”ŸæˆChrome 137çš„å®Œæ•´digestå¥—ä»¶"""
    print("ğŸš€ Chrome 137 Digest ç”Ÿæˆæµ‹è¯•")
    print("=" * 60)
    
    target_version = 137
    target_channel = "stable"
    
    print(f"ğŸ“‹ ç›®æ ‡ç‰ˆæœ¬: Chrome {target_version} {target_channel}")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # åˆ›å»ºå·¥å…·å®ä¾‹
    ctx = MockContext()
    enterprise_tool = EnterpriseDigestTool(BASE_PATH)
    webplatform_tool = WebplatformDigestTool(BASE_PATH)
    merged_tool = MergedDigestHtmlTool(BASE_PATH)
    
    # æ£€æŸ¥æºæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    print("ğŸ” æ£€æŸ¥æºæ•°æ®æ–‡ä»¶...")
    enterprise_source = BASE_PATH / "upstream_docs" / "processed_releasenotes" / "processed_forenterprise" / f"{target_version}-organized_chromechanges-enterprise.md"
    webplatform_source = BASE_PATH / "upstream_docs" / "processed_releasenotes" / "processed_forwebplatform" / f"{target_version}-webplatform-with-webgpu.md"
    
    if not enterprise_source.exists():
        print(f"âŒ ä¼ä¸šç‰ˆæºæ•°æ®ç¼ºå¤±: {enterprise_source}")
        return False
    else:
        print(f"âœ… ä¼ä¸šç‰ˆæºæ•°æ®å­˜åœ¨: {enterprise_source}")
        
    if not webplatform_source.exists():
        print(f"âŒ Webå¹³å°æºæ•°æ®ç¼ºå¤±: {webplatform_source}")
        return False
    else:
        print(f"âœ… Webå¹³å°æºæ•°æ®å­˜åœ¨: {webplatform_source}")
    
    print()
    
    # æ­¥éª¤1: ç”Ÿæˆä¼ä¸šç‰ˆdigest
    print("ğŸ¢ æ­¥éª¤ 1/3: ç”Ÿæˆä¼ä¸šç‰ˆdigest...")
    print("   âš™ï¸  è°ƒç”¨ enterprise_digest tool...")
    
    try:
        enterprise_params = {
            "version": target_version,
            "channel": target_channel,
            "focus_area": "productivity",
            "custom_instruction": "é‡ç‚¹å…³æ³¨ä¼ä¸šç”¨æˆ·çš„ç”Ÿäº§åŠ›æå‡åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç®¡ç†åŠŸèƒ½ã€å®‰å…¨æ€§æ”¹è¿›å’Œéƒ¨ç½²ç›¸å…³çš„å˜æ›´ã€‚è¯·ç”Ÿæˆè¯¦ç»†çš„ä¸­æ–‡digestã€‚"
        }
        
        enterprise_result = await enterprise_tool.generate_digest_with_sampling(ctx, enterprise_params)  # type: ignore
        
        enterprise_data = json.loads(enterprise_result)
        
        if enterprise_data["success"]:
            print(f"   âœ… ä¼ä¸šç‰ˆdigestç”ŸæˆæˆåŠŸ")
            print(f"   ğŸ“„ è¾“å‡ºæ–‡ä»¶: {enterprise_data['output_path']}")
            
            # éªŒè¯æ–‡ä»¶å¹¶æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            output_path = Path(enterprise_data['output_path'])
            if output_path.exists():
                file_size = output_path.stat().st_size
                print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} bytes")
                
                # è¯»å–å¹¶æ˜¾ç¤ºå‰å‡ è¡Œå†…å®¹
                with open(output_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_lines = len(lines)
                    print(f"   ğŸ“ æ€»è¡Œæ•°: {total_lines}")
                    print(f"   ğŸ“– å‰3è¡Œé¢„è§ˆ:")
                    for i, line in enumerate(lines[:3]):
                        print(f"      {i+1}: {line.strip()}")
            else:
                print(f"   âŒ è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                return False
        else:
            print(f"   âŒ ä¼ä¸šç‰ˆdigestç”Ÿæˆå¤±è´¥")
            print(f"   ğŸ” é”™è¯¯ä¿¡æ¯: {enterprise_data.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"   âŒ ä¼ä¸šç‰ˆdigestç”Ÿæˆå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    print()
    
    # æ­¥éª¤2: ç”ŸæˆWebå¹³å°digest
    print("ğŸŒ æ­¥éª¤ 2/3: ç”ŸæˆWebå¹³å°digest...")
    print("   âš™ï¸  è°ƒç”¨ webplatform_digest tool...")
    
    try:
        webplatform_params = {
            "version": target_version,
            "channel": target_channel,
            "focus_areas": ["ai", "webgpu", "css", "performance", "security"],
            "custom_instruction": "é‡ç‚¹å…³æ³¨AIåŠŸèƒ½ã€WebGPUæ”¹è¿›ã€CSSæ–°ç‰¹æ€§ã€æ€§èƒ½ä¼˜åŒ–å’Œå®‰å…¨æ€§æå‡ã€‚è¯·ç”Ÿæˆè¯¦ç»†çš„ä¸­æ–‡digestï¼Œçªå‡ºå¯¹å¼€å‘è€…çš„å½±å“ã€‚"
        }
        
        webplatform_result = await webplatform_tool.generate_digest_with_sampling(ctx, webplatform_params)  # type: ignore
        
        webplatform_data = json.loads(webplatform_result)
        
        if webplatform_data["success"]:
            print(f"   âœ… Webå¹³å°digestç”ŸæˆæˆåŠŸ")
            print(f"   ğŸ“„ è¾“å‡ºæ–‡ä»¶: {webplatform_data['output_path']}")
            
            # éªŒè¯æ–‡ä»¶å¹¶æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            output_path = Path(webplatform_data['output_path'])
            if output_path.exists():
                file_size = output_path.stat().st_size
                print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} bytes")
                
                # è¯»å–å¹¶æ˜¾ç¤ºå‰å‡ è¡Œå†…å®¹
                with open(output_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    total_lines = len(lines)
                    print(f"   ğŸ“ æ€»è¡Œæ•°: {total_lines}")
                    print(f"   ğŸ“– å‰3è¡Œé¢„è§ˆ:")
                    for i, line in enumerate(lines[:3]):
                        print(f"      {i+1}: {line.strip()}")
            else:
                print(f"   âŒ è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                return False
        else:
            print(f"   âŒ Webå¹³å°digestç”Ÿæˆå¤±è´¥")
            print(f"   ğŸ” é”™è¯¯ä¿¡æ¯: {webplatform_data.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"   âŒ Webå¹³å°digestç”Ÿæˆå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    print()
    
    # æ­¥éª¤3: ç”Ÿæˆåˆå¹¶HTML
    print("ğŸ“„ æ­¥éª¤ 3/3: ç”Ÿæˆåˆå¹¶HTML...")
    print("   âš™ï¸  è°ƒç”¨ merged_digest_html tool...")
    
    try:
        html_params = {
            "version": target_version,
            "channel": target_channel,
            "force_regenerate": True,
            "output_dir": "digest_html"
        }
        
        html_result = await merged_tool.generate_html(html_params)
        
        html_data = json.loads(html_result)
        
        if html_data["success"]:
            print(f"   âœ… åˆå¹¶HTMLç”ŸæˆæˆåŠŸ")
            print(f"   ğŸ“„ è¾“å‡ºæ–‡ä»¶: {html_data['output_path']}")
            
            # éªŒè¯HTMLæ–‡ä»¶
            output_path = Path(html_data['output_path'])
            if output_path.exists():
                file_size = output_path.stat().st_size
                print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} bytes")
                
                # éªŒè¯HTMLå†…å®¹ç»“æ„
                with open(output_path, 'r', encoding='utf-8') as f:
                    html_content = f.read()
                
                # åŸºæœ¬HTMLç»“æ„æ£€æŸ¥
                html_checks = [
                    ("<!DOCTYPE html>", "HTML5æ–‡æ¡£å£°æ˜"),
                    ("<title>Chrome 137", "é¡µé¢æ ‡é¢˜"),
                    ("switchDigestType", "Tabåˆ‡æ¢åŠŸèƒ½"),
                    ("enterprise-digest", "ä¼ä¸šç‰ˆå†…å®¹åŒºåŸŸ"),
                    ("webplatform-digest", "Webå¹³å°å†…å®¹åŒºåŸŸ"),
                    ("Bootstrap", "CSSæ¡†æ¶"),
                    ("JavaScript", "äº¤äº’åŠŸèƒ½")
                ]
                
                print("   ğŸ” HTMLç»“æ„éªŒè¯:")
                all_checks_passed = True
                for check_text, description in html_checks:
                    if check_text in html_content:
                        print(f"      âœ… {description}")
                    else:
                        print(f"      âŒ ç¼ºå°‘ {description}")
                        all_checks_passed = False
                
                if all_checks_passed:
                    print("   ğŸ‰ HTMLç»“æ„å®Œæ•´!")
                else:
                    print("   âš ï¸  HTMLç»“æ„å¯èƒ½æœ‰é—®é¢˜")
                    
            else:
                print(f"   âŒ HTMLè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                return False
        else:
            print(f"   âŒ åˆå¹¶HTMLç”Ÿæˆå¤±è´¥")
            print(f"   ğŸ” é”™è¯¯ä¿¡æ¯: {html_data.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"   âŒ åˆå¹¶HTMLç”Ÿæˆå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    print()
    print("ğŸ‰ Chrome 137 Digestç”Ÿæˆå®Œæˆ!")
    print("=" * 60)
    
    # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    print("ğŸ“Š ç”Ÿæˆæ‘˜è¦:")
    print(f"   ğŸ“… å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   ğŸ“‚ ä¼ä¸šç‰ˆMarkdown: digest_markdown/enterprise/digest-chrome-{target_version}-enterprise-{target_channel}.md")
    print(f"   ğŸ“‚ Webå¹³å°Markdown: digest_markdown/webplatform/digest-chrome-{target_version}-webplatform-{target_channel}.md")
    print(f"   ğŸ“‚ åˆå¹¶HTML: digest_html/chrome-{target_version}-merged-digest-{target_channel}.html")
    print()
    print("ğŸš€ ä¸‹ä¸€æ­¥: å¯ä»¥é€šè¿‡æµè§ˆå™¨æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹æ•ˆæœï¼Œæˆ–è€…ç”¨ç¼–è¾‘å™¨æŸ¥çœ‹Markdownæ–‡ä»¶ã€‚")
    
    return True


async def main():
    """ä¸»å‡½æ•°"""
    print("Chrome 137 MCP Tools æµ‹è¯•")
    print("é€šè¿‡FastMCP serverè°ƒç”¨digestç”Ÿæˆå·¥å…·")
    print()
    
    success = await generate_chrome_137_digests()
    
    if success:
        print("\nâœ… æµ‹è¯•æˆåŠŸå®Œæˆ!")
        print("æ‰€æœ‰Chrome 137çš„digestæ–‡ä»¶éƒ½å·²ç”Ÿæˆã€‚")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥!")
        print("è¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯ã€‚")


if __name__ == "__main__":
    asyncio.run(main())
