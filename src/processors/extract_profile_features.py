#!/usr/bin/env python3
"""
Profile Features Extractor
ä»Chrome Enterprise Release Notesä¸­æå–ä¸profileç›¸å…³çš„åŠŸèƒ½ç‰¹æ€§
åŸºäº prompts/profile-keywords.txt ä¸­å®šä¹‰çš„å…³é”®è¯
"""

import re
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Set, Optional
from dataclasses import dataclass
from datetime import datetime

# é‡ç”¨å·²æœ‰çš„Featureæ•°æ®ç»“æ„
sys.path.append(str(Path(__file__).parent.parent))
from process_enterprise_release_note import (
    Feature, 
    EnterpriseReleaseNotesProcessor as ReleaseNotesProcessorV2
)


@dataclass
class ProfileFeature:
    """Profileç›¸å…³çš„ç‰¹æ€§ï¼Œç»§æ‰¿è‡ªFeatureå¹¶æ·»åŠ åŒ¹é…ä¿¡æ¯"""
    feature: Feature
    matched_keywords: List[str]
    relevance_score: float
    match_context: str  # åŒ¹é…åˆ°å…³é”®è¯çš„ä¸Šä¸‹æ–‡


class ProfileFeatureExtractor:
    """Profileç‰¹æ€§æå–å™¨"""
    
    def __init__(self, keywords_file: str = None):
        """åˆå§‹åŒ–æå–å™¨"""
        self.keywords_file = keywords_file or self._get_default_keywords_file()
        self.profile_keywords = self._load_keywords()
        self.processor = ReleaseNotesProcessorV2()
        
    def _get_default_keywords_file(self) -> str:
        """è·å–é»˜è®¤å…³é”®è¯æ–‡ä»¶è·¯å¾„"""
        base_path = Path(__file__).parent.parent
        return str(base_path / "prompts" / "profile-keywords.txt")
    
    def _load_keywords(self) -> str:
        """åŠ è½½profileå…³é”®è¯"""
        try:
            with open(self.keywords_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾æ ¸å¿ƒå…³é”®è¯ç»„åˆè¡Œ
            for line in content.split('\n'):
                line = line.strip()
                if not line.startswith('#') and '|' in line and 'profile' in line.lower():
                    print(f"Loaded profile keywords: {line}")
                    return line
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯
            default_keywords = "profile|Profile|account|Account|identity|Identity|sync|Sync|sign-in|signin|multiple.*account|separate.*profile|data.*separation"
            print(f"Using default keywords: {default_keywords}")
            return default_keywords
            
        except FileNotFoundError:
            print(f"Warning: Keywords file not found: {self.keywords_file}")
            default_keywords = "profile|Profile|account|Account|identity|Identity|sync|Sync|sign-in|signin"
            print(f"Using fallback keywords: {default_keywords}")
            return default_keywords
    
    def _calculate_relevance_score(self, feature: Feature, matched_keywords: List[str], 
                                 match_context: str) -> float:
        """è®¡ç®—ç‰¹æ€§ä¸profileçš„ç›¸å…³æ€§å¾—åˆ†"""
        score = 0.0
        
        # åŸºç¡€åŒ¹é…å¾—åˆ† - æ¯ä¸ªå…³é”®è¯åŒ¹é…åŠ åˆ†
        score += len(matched_keywords) * 10
        
        # æ ‡é¢˜ä¸­çš„åŒ¹é…æƒé‡æ›´é«˜
        title_lower = feature.title.lower()
        for keyword in matched_keywords:
            if keyword.lower() in title_lower:
                score += 20
        
        # ç‰¹å®šé«˜ä»·å€¼å…³é”®è¯åŠ åˆ†
        high_value_keywords = ['profile', 'multiple.*account', 'separate.*profile', 'data.*separation']
        for hvk in high_value_keywords:
            if any(re.search(hvk, kw, re.IGNORECASE) for kw in matched_keywords):
                score += 15
        
        # ç®¡ç†ç±»åˆ«çš„profileåŠŸèƒ½é€šå¸¸æ›´é‡è¦
        if "Management" in feature.categories:
            score += 10
        
        # æè¿°é•¿åº¦å½±å“ï¼ˆæ›´è¯¦ç»†çš„æè¿°é€šå¸¸æ›´é‡è¦ï¼‰
        if len(feature.description) > 200:
            score += 5
        
        return score
    
    def _extract_match_context(self, text: str, keyword: str, context_length: int = 100) -> str:
        """æå–å…³é”®è¯åŒ¹é…çš„ä¸Šä¸‹æ–‡"""
        pattern = re.compile(f'({re.escape(keyword)})', re.IGNORECASE)
        match = pattern.search(text)
        
        if match:
            start = max(0, match.start() - context_length)
            end = min(len(text), match.end() + context_length)
            context = text[start:end].strip()
            
            # é«˜äº®åŒ¹é…çš„å…³é”®è¯
            context = pattern.sub(r'**\1**', context)
            return context
        
        return ""
    
    def _is_profile_related(self, feature: Feature) -> tuple[bool, List[str], str]:
        """åˆ¤æ–­featureæ˜¯å¦ä¸profileç›¸å…³"""
        # ç»„åˆæ‰€æœ‰æ–‡æœ¬è¿›è¡Œæœç´¢
        search_text = f"{feature.title} {feature.description}"
        
        # æŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯
        matched_keywords = []
        match_contexts = []
        
        # å°†å…³é”®è¯æ¨¡å¼åˆ†å‰²å¹¶é€ä¸€åŒ¹é…
        keyword_patterns = self.profile_keywords.split('|')
        
        for pattern in keyword_patterns:
            pattern = pattern.strip()
            if not pattern:
                continue
                
            # æœç´¢åŒ¹é…
            matches = re.finditer(pattern, search_text, re.IGNORECASE)
            for match in matches:
                matched_keyword = match.group()
                if matched_keyword not in matched_keywords:
                    matched_keywords.append(matched_keyword)
                    context = self._extract_match_context(search_text, matched_keyword)
                    if context:
                        match_contexts.append(context)
        
        # å¦‚æœæœ‰åŒ¹é…çš„å…³é”®è¯ï¼Œåˆ™è®¤ä¸ºæ˜¯profileç›¸å…³
        is_related = len(matched_keywords) > 0
        context = " | ".join(match_contexts[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªä¸Šä¸‹æ–‡
        
        return is_related, matched_keywords, context
    
    def extract_from_processed_features(self, features: Dict[str, Feature]) -> List[ProfileFeature]:
        """ä»å·²å¤„ç†çš„featuresä¸­æå–profileç›¸å…³ç‰¹æ€§"""
        profile_features = []
        
        for feature_name, feature in features.items():
            is_related, matched_keywords, context = self._is_profile_related(feature)
            
            if is_related:
                # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
                score = self._calculate_relevance_score(feature, matched_keywords, context)
                
                profile_feature = ProfileFeature(
                    feature=feature,
                    matched_keywords=matched_keywords,
                    relevance_score=score,
                    match_context=context
                )
                profile_features.append(profile_feature)
                
                print(f"Found profile feature: {feature_name} (score: {score:.1f})")
                print(f"  Keywords: {matched_keywords}")
                print(f"  Context: {context[:100]}...")
        
        # æŒ‰ç›¸å…³æ€§å¾—åˆ†æ’åº
        profile_features.sort(key=lambda x: x.relevance_score, reverse=True)
        return profile_features
    
    def parse_processed_file(self, file_path: str) -> Dict[str, Feature]:
        """è§£æå·²å¤„ç†çš„markdownæ–‡ä»¶"""
        features = {}
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–ç‰ˆæœ¬å·
        version_match = re.search(r'Chrome (\d+)', content)
        chrome_version = int(version_match.group(1)) if version_match else 138
        
        # è§£æfeatures
        # æŒ‰ ### åˆ†å‰²sections
        sections = re.split(r'^### (.+)$', content, flags=re.MULTILINE)
        
        current_category = None
        for i in range(1, len(sections), 2):
            if i + 1 < len(sections):
                category = sections[i].strip()
                section_content = sections[i + 1].strip()
                
                if category in ["User productivity/Apps", "Security/Privacy", "Management"]:
                    current_category = category
                    
                    # è§£æè¿™ä¸ªcategoryä¸‹çš„features
                    features.update(self._parse_category_features(section_content, current_category, chrome_version))
        
        return features
    
    def _parse_category_features(self, content: str, category: str, chrome_version: int) -> Dict[str, Feature]:
        """è§£æå•ä¸ªcategoryä¸‹çš„features"""
        features = {}
        
        # æŒ‰ * ** åˆ†å‰²features
        feature_blocks = re.split(r'\n\* \*\*(.+?)\*\*', content)
        
        for i in range(1, len(feature_blocks), 2):
            if i + 1 < len(feature_blocks):
                title = feature_blocks[i].strip()
                feature_content = feature_blocks[i + 1].strip()
                
                # ç¡®å®šçŠ¶æ€
                status = "upcoming" if "Upcoming" in content[:200] else "current"
                
                # è§£æfeatureå†…å®¹
                feature = self._parse_single_feature(title, feature_content, category, status, chrome_version)
                if feature:
                    features[title] = feature
        
        return features
    
    def _parse_single_feature(self, title: str, content: str, category: str, 
                            status: str, chrome_version: int) -> Optional[Feature]:
        """è§£æå•ä¸ªfeature"""
        try:
            # æå–ç±»å‹
            type_match = re.search(r'â€¢ Type: (.+)', content)
            change_type = type_match.group(1) if type_match else "Chrome Browser changes"
            
            # æå–å¹³å°
            platform_match = re.search(r'â€¢ Platform: (.+)', content)
            platforms = []
            if platform_match:
                platform_text = platform_match.group(1)
                # è§£æå¹³å°ä¿¡æ¯
                desktop_match = re.search(r'Desktop \(([^)]+)\)', platform_text)
                mobile_match = re.search(r'Mobile \(([^)]+)\)', platform_text)
                
                if desktop_match:
                    platforms.extend([p.strip() for p in desktop_match.group(1).split(',')])
                if mobile_match:
                    platforms.extend([p.strip() for p in mobile_match.group(1).split(',')])
            
            # æå–æè¿°
            update_match = re.search(r'â€¢ Update: (.+)', content, re.DOTALL)
            description = update_match.group(1).strip() if update_match else ""
            
            # æå–policy
            policy_match = re.search(r'`([A-Za-z]+[A-Za-z0-9]*)`', description)
            policy = policy_match.group(1) if policy_match else None
            
            # æå–ç‰ˆæœ¬ä¿¡æ¯
            version_info = None
            if status == "upcoming":
                version_match = re.search(r'Chrome (\d+)', description)
                if version_match:
                    version_info = f"Chrome {version_match.group(1)}"
            
            feature = Feature(
                title=title,
                change_type=change_type,
                categories=[category],
                status=status,
                platforms=platforms,
                description=description,
                policy=policy,
                version_info=version_info
            )
            
            return feature
            
        except Exception as e:
            print(f"Error parsing feature '{title}': {e}")
            return None
    
    def process_release_notes(self, file_path: str) -> List[ProfileFeature]:
        """å¤„ç†å·²å¤„ç†çš„release notesæ–‡ä»¶å¹¶æå–profileç›¸å…³ç‰¹æ€§"""
        print(f"Processing processed file: {file_path}")
        
        # è§£æå·²å¤„ç†çš„markdownæ–‡ä»¶
        features = self.parse_processed_file(file_path)
        
        print(f"Total features found: {len(features)}")
        
        # æå–profileç›¸å…³ç‰¹æ€§
        profile_features = self.extract_from_processed_features(features)
        
        print(f"Profile-related features found: {len(profile_features)}")
        return profile_features
    
    def generate_profile_report(self, profile_features: List[ProfileFeature], 
                              chrome_version: int = None) -> str:
        """ç”Ÿæˆprofileç‰¹æ€§æŠ¥å‘Š"""
        if not chrome_version:
            chrome_version = self.processor.current_version or "Unknown"
        
        # ç”ŸæˆæŠ¥å‘Š
        report = []
        report.append(f"# Chrome {chrome_version} Profile-Related Features Report")
        report.append(f"")
        report.append(f"*Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
        report.append(f"")
        report.append(f"## Summary")
        report.append(f"")
        report.append(f"- **Total features analyzed**: {len(self.processor.features)}")
        report.append(f"- **Profile-related features found**: {len(profile_features)}")
        report.append(f"- **Keywords used**: `{self.profile_keywords}`")
        report.append(f"")
        
        if not profile_features:
            report.append("No profile-related features found in this release.")
            return '\n'.join(report)
        
        # æŒ‰ç±»åˆ«ç»„ç»‡ç‰¹æ€§
        categories = {
            "User productivity/Apps": [],
            "Security/Privacy": [],
            "Management": []
        }
        
        for pf in profile_features:
            for category in pf.feature.categories:
                if category in categories:
                    categories[category].append(pf)
        
        # å¤„ç†æ²¡æœ‰åˆ†ç±»æˆ–ä¸åœ¨ä¸»è¦åˆ†ç±»ä¸­çš„ç‰¹æ€§
        uncategorized = []
        for pf in profile_features:
            if not pf.feature.categories or not any(cat in categories for cat in pf.feature.categories):
                uncategorized.append(pf)
        
        # ç”Ÿæˆå„ä¸ªåˆ†ç±»çš„æŠ¥å‘Š
        for category, features in categories.items():
            if not features:
                continue
                
            report.append(f"## {category}")
            report.append(f"")
            
            for pf in sorted(features, key=lambda x: x.relevance_score, reverse=True):
                report.append(self._format_profile_feature(pf))
                report.append("")
        
        # å¤„ç†æœªåˆ†ç±»çš„ç‰¹æ€§
        if uncategorized:
            report.append(f"## Other Profile Features")
            report.append(f"")
            
            for pf in sorted(uncategorized, key=lambda x: x.relevance_score, reverse=True):
                report.append(self._format_profile_feature(pf))
                report.append("")
        
        # æ·»åŠ å…³é”®è¯ç»Ÿè®¡
        report.append(f"## Keyword Analysis")
        report.append(f"")
        
        # ç»Ÿè®¡å…³é”®è¯é¢‘ç‡
        keyword_counts = {}
        for pf in profile_features:
            for keyword in pf.matched_keywords:
                keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
        
        # æŒ‰é¢‘ç‡æ’åº
        sorted_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)
        
        report.append("| Keyword | Frequency |")
        report.append("|---------|-----------|")
        for keyword, count in sorted_keywords:
            report.append(f"| {keyword} | {count} |")
        
        return '\n'.join(report)
    
    def _format_profile_feature(self, pf: ProfileFeature) -> str:
        """æ ¼å¼åŒ–å•ä¸ªprofileç‰¹æ€§"""
        feature = pf.feature
        
        lines = []
        lines.append(f"### {feature.title}")
        lines.append(f"")
        lines.append(f"**Relevance Score**: {pf.relevance_score:.1f}")
        lines.append(f"")
        lines.append(f"**Type**: {feature.change_type}")
        
        if feature.platforms:
            platform_info = self._format_platforms(feature.platforms)
            lines.append(f"**Platform**: {platform_info}")
        
        lines.append(f"**Status**: {feature.status.title()}")
        
        if feature.categories:
            lines.append(f"**Categories**: {', '.join(feature.categories)}")
        
        if pf.matched_keywords:
            lines.append(f"**Matched Keywords**: {', '.join(pf.matched_keywords)}")
        
        lines.append(f"")
        lines.append(f"**Description**:")
        lines.append(f"{feature.description}")
        
        if pf.match_context:
            lines.append(f"")
            lines.append(f"**Key Context**: {pf.match_context}")
        
        if feature.policy:
            lines.append(f"")
            lines.append(f"**Related Policy**: `{feature.policy}`")
        
        if feature.version_info:
            lines.append(f"")
            lines.append(f"**Version Info**: {feature.version_info}")
        
        return '\n'.join(lines)
    
    def _format_platforms(self, platforms: List[str]) -> str:
        """æ ¼å¼åŒ–å¹³å°ä¿¡æ¯"""
        desktop_platforms = []
        mobile_platforms = []
        
        platform_mapping = {
            'Windows': 'desktop', 'macOS': 'desktop', 'Linux': 'desktop', 'ChromeOS': 'desktop',
            'Android': 'mobile', 'iOS': 'mobile'
        }
        
        for platform in platforms:
            if platform_mapping.get(platform) == 'desktop':
                desktop_platforms.append(platform)
            elif platform_mapping.get(platform) == 'mobile':
                mobile_platforms.append(platform)
        
        platform_parts = []
        if desktop_platforms:
            platform_parts.append(f"Desktop ({', '.join(sorted(desktop_platforms))})")
        if mobile_platforms:
            platform_parts.append(f"Mobile ({', '.join(sorted(mobile_platforms))})")
        
        return ', '.join(platform_parts) if platform_parts else 'All platforms'


def find_processed_files():
    """æŸ¥æ‰¾å·²å¤„ç†çš„æ–‡ä»¶"""
    base_path = Path("/Users/lyzh/Documents/Nova_Projects/chrome-update-digest")
    processed_dir = base_path / "upstream_docs" / "processed_forenterprise"
    
    processed_files = {}
    for file in processed_dir.glob("*-organized_chromechanges-enterprise.md"):
        # æå–ç‰ˆæœ¬å·
        match = re.search(r'^(\d+)-organized_chromechanges-enterprise\.md$', file.name)
        if match:
            version = int(match.group(1))
            processed_files[version] = file
    
    return processed_files


def main():
    parser = argparse.ArgumentParser(description='Extract profile-related features from Chrome Enterprise release notes')
    parser.add_argument('version', nargs='?', type=int, help='Chrome version to process (e.g., 137, 138)')
    parser.add_argument('--all', action='store_true', help='Process all available versions')
    parser.add_argument('--keywords', help='Path to keywords file (default: prompts/profile-keywords.txt)')
    parser.add_argument('--output', help='Output directory (default: profile_reports/)')
    parser.add_argument('--list', action='store_true', help='List available versions')
    
    args = parser.parse_args()
    
    # æŸ¥æ‰¾å·²å¤„ç†çš„æ–‡ä»¶
    processed_files = find_processed_files()
    
    if args.list:
        if processed_files:
            print("Available processed Chrome versions:")
            for version in sorted(processed_files.keys()):
                print(f"  - Chrome {version}: {processed_files[version].name}")
        else:
            print("No processed files found.")
        return
    
    # ç¡®å®šè¦å¤„ç†çš„ç‰ˆæœ¬
    versions_to_process = []
    if args.version:
        if args.version in processed_files:
            versions_to_process = [args.version]
        else:
            print(f"Error: Chrome {args.version} processed file not found.")
            print(f"Available versions: {sorted(processed_files.keys())}")
            sys.exit(1)
    elif args.all:
        versions_to_process = sorted(processed_files.keys())
    else:
        # é»˜è®¤å¤„ç†æœ€æ–°ç‰ˆæœ¬
        if processed_files:
            latest_version = max(processed_files.keys())
            versions_to_process = [latest_version]
            print(f"No version specified. Processing latest: Chrome {latest_version}")
        else:
            print("No processed files found.")
            return
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = Path(args.output) if args.output else Path("profile_reports")
    output_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºæå–å™¨
    extractor = ProfileFeatureExtractor(keywords_file=args.keywords)
    
    # å¤„ç†æ¯ä¸ªç‰ˆæœ¬
    for version in versions_to_process:
        input_file = processed_files[version]
        output_file = output_dir / f"chrome-{version}-profile-features.md"
        
        print(f"\n{'='*60}")
        print(f"Processing Chrome {version}")
        print(f"Input: {input_file}")
        print(f"Output: {output_file}")
        print(f"{'='*60}")
        
        try:
            # æå–profileç›¸å…³ç‰¹æ€§
            profile_features = extractor.process_release_notes(str(input_file))
            
            # ç”ŸæˆæŠ¥å‘Š
            report = extractor.generate_profile_report(profile_features, version)
            
            # å†™å…¥æ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"âœ… Profile report generated: {output_file.name}")
            print(f"âœ… Found {len(profile_features)} profile-related features")
            
            if profile_features:
                print(f"âœ… Top features by relevance:")
                for i, pf in enumerate(profile_features[:3], 1):
                    print(f"   {i}. {pf.feature.title} (score: {pf.relevance_score:.1f})")
            
        except Exception as e:
            print(f"âŒ Error processing Chrome {version}: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ‰ Profile feature extraction complete!")
    print(f"[DIR] Reports saved to: {output_dir}")


if __name__ == "__main__":
    main()